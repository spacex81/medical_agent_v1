{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cbf57f2-3cc5-4432-9dd3-7ef6e8efeddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "print(\"=== DEBUG DUR API EXTRACTION ===\")\n",
    "\n",
    "# API Configuration\n",
    "SERVICE_KEY = \"h9Dbf2cz0HOrqZb5BIqrfrti%2FD5zZLTYAxFpQuywAB7ZUx3yb67jBDuD5uNlHvAszz9c14NffOmMNQjGv5FzwA%3D%3D\"\n",
    "BASE_URL = \"https://apis.data.go.kr/1471000/DURIrdntInfoService03/getUsjntTabooInfoList02\"\n",
    "\n",
    "def debug_api_call():\n",
    "    \"\"\"Debug the API call to understand what's going wrong\"\"\"\n",
    "    \n",
    "    print(f\"\\n1. Testing API connectivity...\")\n",
    "    print(f\"   URL: {BASE_URL}\")\n",
    "    \n",
    "    # Test with minimal parameters first\n",
    "    params = {\n",
    "        \"serviceKey\": SERVICE_KEY,\n",
    "        \"pageNo\": 1,\n",
    "        \"numOfRows\": 1,  # Start with just 1 record\n",
    "        \"type\": \"json\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n2. API Parameters:\")\n",
    "    for key, value in params.items():\n",
    "        if key == \"serviceKey\":\n",
    "            print(f\"   {key}: {value[:20]}...{value[-10:]}\")  # Mask most of the service key\n",
    "        else:\n",
    "            print(f\"   {key}: {value}\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n3. Making API request...\")\n",
    "        \n",
    "        # Add headers that might be required\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'application/json, text/plain, */*',\n",
    "            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(BASE_URL, params=params, headers=headers, timeout=30)\n",
    "        \n",
    "        print(f\"   Status Code: {response.status_code}\")\n",
    "        print(f\"   Content Type: {response.headers.get('content-type', 'Not specified')}\")\n",
    "        print(f\"   Content Length: {len(response.content)} bytes\")\n",
    "        \n",
    "        # Print first 500 characters of response\n",
    "        print(f\"\\n4. Response Preview:\")\n",
    "        response_text = response.text\n",
    "        print(f\"   First 500 characters:\")\n",
    "        print(f\"   {repr(response_text[:500])}\")\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"\\n‚ùå HTTP Error {response.status_code}\")\n",
    "            print(f\"   Response: {response_text}\")\n",
    "            return None\n",
    "        \n",
    "        # Try to parse as JSON\n",
    "        print(f\"\\n5. Attempting JSON parsing...\")\n",
    "        try:\n",
    "            data = response.json()\n",
    "            print(f\"   ‚úÖ JSON parsing successful!\")\n",
    "            \n",
    "            # Analyze the structure\n",
    "            print(f\"\\n6. JSON Structure Analysis:\")\n",
    "            print(f\"   Top-level keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dictionary'}\")\n",
    "            \n",
    "            if 'header' in data:\n",
    "                header = data['header']\n",
    "                print(f\"   Header: {header}\")\n",
    "                \n",
    "            if 'body' in data:\n",
    "                body = data['body']\n",
    "                print(f\"   Body keys: {list(body.keys()) if isinstance(body, dict) else 'Not a dictionary'}\")\n",
    "                \n",
    "                if 'totalCount' in body:\n",
    "                    print(f\"   Total count: {body['totalCount']}\")\n",
    "                    \n",
    "                if 'items' in body:\n",
    "                    items = body['items']\n",
    "                    print(f\"   Items count: {len(items) if isinstance(items, list) else 'Not a list'}\")\n",
    "                    \n",
    "                    if isinstance(items, list) and len(items) > 0:\n",
    "                        first_item = items[0]\n",
    "                        print(f\"   First item keys: {list(first_item.keys()) if isinstance(first_item, dict) else 'Not a dictionary'}\")\n",
    "                        print(f\"   First item preview: {str(first_item)[:200]}...\")\n",
    "            \n",
    "            return data\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"   ‚ùå JSON parsing failed: {str(e)}\")\n",
    "            print(f\"   Raw response: {response_text}\")\n",
    "            return None\n",
    "            \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"   ‚ùå Request failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def test_different_approaches():\n",
    "    \"\"\"Test different API call approaches\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== TESTING DIFFERENT APPROACHES ===\")\n",
    "    \n",
    "    # Approach 1: Without URL encoding in service key\n",
    "    print(f\"\\n1. Testing with decoded service key...\")\n",
    "    \n",
    "    # The service key might need to be URL decoded\n",
    "    import urllib.parse\n",
    "    decoded_key = urllib.parse.unquote(SERVICE_KEY)\n",
    "    \n",
    "    params_decoded = {\n",
    "        \"serviceKey\": decoded_key,\n",
    "        \"pageNo\": 1,\n",
    "        \"numOfRows\": 1,\n",
    "        \"type\": \"json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params_decoded, timeout=30)\n",
    "        print(f\"   Status: {response.status_code}\")\n",
    "        print(f\"   Response preview: {response.text[:200]}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                print(f\"   ‚úÖ Success with decoded key!\")\n",
    "                return data\n",
    "            except:\n",
    "                print(f\"   ‚ùå Still not JSON\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed: {str(e)}\")\n",
    "    \n",
    "    # Approach 2: Test the exact URL from documentation\n",
    "    print(f\"\\n2. Testing exact URL from documentation...\")\n",
    "    \n",
    "    # Build URL manually to match documentation exactly\n",
    "    test_url = f\"{BASE_URL}?serviceKey={SERVICE_KEY}&pageNo=1&numOfRows=1&type=json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(test_url, timeout=30)\n",
    "        print(f\"   Status: {response.status_code}\")\n",
    "        print(f\"   Response preview: {response.text[:200]}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                print(f\"   ‚úÖ Success with manual URL!\")\n",
    "                return data\n",
    "            except:\n",
    "                print(f\"   ‚ùå Still not JSON\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed: {str(e)}\")\n",
    "    \n",
    "    # Approach 3: Check if service key is valid by testing a simple endpoint\n",
    "    print(f\"\\n3. Testing service key validity...\")\n",
    "    \n",
    "    # Sometimes the issue is with the service key itself\n",
    "    print(f\"   Service key format check:\")\n",
    "    print(f\"   Length: {len(SERVICE_KEY)}\")\n",
    "    print(f\"   Contains %3D: {'%3D' in SERVICE_KEY}\")\n",
    "    print(f\"   Contains %2F: {'%2F' in SERVICE_KEY}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main debug function\"\"\"\n",
    "    \n",
    "    # Step 1: Basic API debugging\n",
    "    result = debug_api_call()\n",
    "    \n",
    "    if result is None:\n",
    "        # Step 2: Try different approaches\n",
    "        result = test_different_approaches()\n",
    "    \n",
    "    if result is not None:\n",
    "        print(f\"\\n=== SUCCESS! ===\")\n",
    "        print(f\"API is working. Here's the successful response structure:\")\n",
    "        print(json.dumps(result, indent=2, ensure_ascii=False)[:1000])\n",
    "        \n",
    "        # If successful, we can proceed with the full extraction\n",
    "        print(f\"\\n‚úÖ Ready to proceed with full data extraction!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n=== TROUBLESHOOTING SUGGESTIONS ===\")\n",
    "        print(f\"1. ‚úÖ Check if the service key is still valid\")\n",
    "        print(f\"2. ‚úÖ Verify the API endpoint URL is correct\")  \n",
    "        print(f\"3. ‚úÖ Confirm API service is operational\")\n",
    "        print(f\"4. ‚úÖ Test from a different network/IP address\")\n",
    "        print(f\"5. ‚úÖ Contact API provider for support\")\n",
    "        \n",
    "        print(f\"\\nüìß API Provider: data.go.kr\")\n",
    "        print(f\"üîë Service Key (partial): {SERVICE_KEY[:20]}...{SERVICE_KEY[-10:]}\")\n",
    "\n",
    "# Execute the debug\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9464c71-3ee4-4a1c-899c-c5f5c54db05b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "print(\"=== DUR API EXTRACTION - DRUG INTERACTION CONTRAINDICATIONS ===\")\n",
    "\n",
    "# API Configuration - FIXED: Use decoded service key\n",
    "ENCODED_SERVICE_KEY = \"h9Dbf2cz0HOrqZb5BIqrfrti%2FD5zZLTYAxFpQuywAB7ZUx3yb67jBDuD5uNlHvAszz9c14NffOmMNQjGv5FzwA%3D%3D\"\n",
    "SERVICE_KEY = urllib.parse.unquote(ENCODED_SERVICE_KEY)  # This was the fix!\n",
    "BASE_URL = \"https://apis.data.go.kr/1471000/DURIrdntInfoService03/getUsjntTabooInfoList02\"\n",
    "BRONZE_TABLE_NAME = \"main.default.dur_ingredient_interaction_bronze\"\n",
    "\n",
    "print(f\"\\nTarget API: {BASE_URL}\")\n",
    "print(f\"Bronze table: {BRONZE_TABLE_NAME}\")\n",
    "print(f\"Expected records: 1,587\")\n",
    "\n",
    "def make_api_call(page_no, num_rows=100):\n",
    "    \"\"\"Make a single API call with error handling\"\"\"\n",
    "    params = {\n",
    "        \"serviceKey\": SERVICE_KEY,  # Using decoded key\n",
    "        \"pageNo\": page_no,\n",
    "        \"numOfRows\": num_rows,\n",
    "        \"type\": \"json\"\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "        'Accept': 'application/json, */*',\n",
    "        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"   üì° API Call - Page {page_no} (requesting {num_rows} records)\")\n",
    "        response = requests.get(BASE_URL, params=params, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse JSON response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check API response status\n",
    "        header = data.get(\"header\", {})\n",
    "        if header.get(\"resultCode\") != \"00\":\n",
    "            raise Exception(f\"API Error: {header.get('resultMsg', 'Unknown error')}\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"   ‚ùå Network error: {str(e)}\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"   ‚ùå JSON parsing error: {str(e)}\")\n",
    "        print(f\"   Raw response: {response.text[:200]}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå API call failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def extract_all_data():\n",
    "    \"\"\"Extract all data using pagination\"\"\"\n",
    "    print(f\"\\nüöÄ Starting data extraction...\")\n",
    "    \n",
    "    all_records = []\n",
    "    page_no = 1\n",
    "    total_count = None\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Respectful delay between API calls\n",
    "            if page_no > 1:\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            data = make_api_call(page_no)\n",
    "            \n",
    "            # Get total count from first response\n",
    "            body = data.get(\"body\", {})\n",
    "            if total_count is None:\n",
    "                total_count = body.get(\"totalCount\", 0)\n",
    "                estimated_pages = (total_count + 99) // 100\n",
    "                print(f\"   üìä Total records available: {total_count:,}\")\n",
    "                print(f\"   üìÑ Estimated pages needed: {estimated_pages}\")\n",
    "            \n",
    "            # Extract items from response\n",
    "            items = body.get(\"items\", [])\n",
    "            \n",
    "            if not items:\n",
    "                print(f\"   ‚úÖ No more data found at page {page_no}\")\n",
    "                break\n",
    "            \n",
    "            # Process items - extract from nested structure\n",
    "            page_records = []\n",
    "            for item_wrapper in items:\n",
    "                if \"item\" in item_wrapper:\n",
    "                    page_records.append(item_wrapper[\"item\"])\n",
    "                else:\n",
    "                    page_records.append(item_wrapper)\n",
    "            \n",
    "            all_records.extend(page_records)\n",
    "            records_collected = len(all_records)\n",
    "            \n",
    "            print(f\"   ‚úÖ Page {page_no}: +{len(page_records)} records | Total: {records_collected:,}/{total_count:,}\")\n",
    "            \n",
    "            # Check if we've collected all records\n",
    "            if records_collected >= total_count:\n",
    "                print(f\"   üéâ All records collected successfully!\")\n",
    "                break\n",
    "            \n",
    "            page_no += 1\n",
    "            \n",
    "            # Safety check\n",
    "            if page_no > 20:  # Should only need ~16 pages\n",
    "                print(f\"   ‚ö†Ô∏è  Safety break at page {page_no}\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error on page {page_no}: {str(e)}\")\n",
    "            \n",
    "            # Try to continue with next page for transient errors\n",
    "            if \"timeout\" in str(e).lower() or \"connection\" in str(e).lower():\n",
    "                print(f\"   üîÑ Retrying in 2 seconds...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"   üõë Stopping extraction due to persistent error\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nüìã Extraction Summary:\")\n",
    "    print(f\"   Pages processed: {page_no}\")\n",
    "    print(f\"   Records extracted: {len(all_records):,}\")\n",
    "    print(f\"   Completeness: {len(all_records)/total_count*100:.1f}%\" if total_count else \"N/A\")\n",
    "    \n",
    "    return all_records, total_count\n",
    "\n",
    "def create_bronze_table(records, expected_count):\n",
    "    \"\"\"Convert records to DataFrame and create bronze table\"\"\"\n",
    "    print(f\"\\nüèóÔ∏è  Creating bronze table...\")\n",
    "    \n",
    "    if not records:\n",
    "        print(\"   ‚ùå No records to process\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Convert to Spark DataFrame\n",
    "        print(f\"   üìä Converting {len(records):,} records to Spark DataFrame...\")\n",
    "        df = spark.createDataFrame(records)\n",
    "        \n",
    "        record_count = df.count()\n",
    "        column_count = len(df.columns)\n",
    "        \n",
    "        print(f\"   ‚úÖ DataFrame created successfully!\")\n",
    "        print(f\"      Records: {record_count:,}\")\n",
    "        print(f\"      Columns: {column_count}\")\n",
    "        \n",
    "        # Display schema\n",
    "        print(f\"\\n   üìã Schema:\")\n",
    "        df.printSchema()\n",
    "        \n",
    "        # Show sample data\n",
    "        print(f\"\\n   üìù Sample Records (first 3):\")\n",
    "        df.select(\"INGR_KOR_NAME\", \"INGR_ENG_NAME\", \"MIXTURE_INGR_KOR_NAME\", \"PROHBT_CONTENT\").show(3, truncate=False)\n",
    "        \n",
    "        # Write to bronze table\n",
    "        print(f\"\\n   üíæ Writing to bronze table: {BRONZE_TABLE_NAME}\")\n",
    "        \n",
    "        df.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .saveAsTable(BRONZE_TABLE_NAME)\n",
    "        \n",
    "        print(f\"   ‚úÖ Bronze table created successfully!\")\n",
    "        \n",
    "        # Verify the table\n",
    "        print(f\"\\nüîç Verification:\")\n",
    "        bronze_df = spark.table(BRONZE_TABLE_NAME)\n",
    "        verified_count = bronze_df.count()\n",
    "        \n",
    "        print(f\"   Records in bronze table: {verified_count:,}\")\n",
    "        print(f\"   Expected records: {expected_count:,}\")\n",
    "        print(f\"   Data integrity: {'‚úÖ Perfect' if verified_count == len(records) else '‚ö†Ô∏è Check needed'}\")\n",
    "        print(f\"   Completeness: {verified_count/expected_count*100:.1f}%\")\n",
    "        \n",
    "        # Business intelligence preview\n",
    "        print(f\"\\nüìä Data Insights:\")\n",
    "        \n",
    "        # Mix type distribution\n",
    "        print(f\"   Mix Types:\")\n",
    "        bronze_df.groupBy(\"MIX_TYPE\").count().orderBy(desc(\"count\")).show()\n",
    "        \n",
    "        # Top drug interactions\n",
    "        print(f\"   Most Common Drug Interactions:\")\n",
    "        bronze_df.groupBy(\"INGR_KOR_NAME\", \"MIXTURE_INGR_KOR_NAME\") \\\n",
    "                .count() \\\n",
    "                .orderBy(desc(\"count\")) \\\n",
    "                .select(\"INGR_KOR_NAME\", \"MIXTURE_INGR_KOR_NAME\") \\\n",
    "                .show(5, truncate=False)\n",
    "        \n",
    "        # Drug classes involved\n",
    "        print(f\"   Drug Classes Distribution:\")\n",
    "        bronze_df.groupBy(\"CLASS\").count().orderBy(desc(\"count\")).show(5, truncate=False)\n",
    "        \n",
    "        return bronze_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error creating bronze table: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(f\"‚è∞ Started at: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        # Extract all data from API  \n",
    "        records, expected_count = extract_all_data()\n",
    "        \n",
    "        if records:\n",
    "            # Create bronze table\n",
    "            bronze_df = create_bronze_table(records, expected_count)\n",
    "            \n",
    "            # Final summary\n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "            \n",
    "            print(f\"\\nüéâ === EXTRACTION COMPLETED SUCCESSFULLY ===\")\n",
    "            print(f\"üìã Summary:\")\n",
    "            print(f\"   ‚úÖ Bronze table: {BRONZE_TABLE_NAME}\")\n",
    "            print(f\"   üìä Records extracted: {len(records):,}\")\n",
    "            print(f\"   üìà Completeness: {len(records)/expected_count*100:.1f}%\")\n",
    "            print(f\"   ‚è±Ô∏è Processing time: {processing_time:.1f} seconds\")\n",
    "            print(f\"   üöÄ Performance: {len(records)/processing_time:.0f} records/second\")\n",
    "            print(f\"   üíæ Ready for silver layer transformations!\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n‚ùå EXTRACTION FAILED: No data retrieved\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nüí• EXTRACTION FAILED: {str(e)}\")\n",
    "        print(f\"üîß Check API connectivity and service key validity\")\n",
    "        raise\n",
    "\n",
    "# Execute the extraction\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dur_ingredient_test_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
