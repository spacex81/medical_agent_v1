{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14a587f3-9194-466b-9811-13b29e11f884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "print(\"=== DUR PRODUCT INFO - FIXED API 6: ADMINISTRATION PERIOD PRECAUTIONS ===\")\n",
    "\n",
    "# API Configuration\n",
    "ENCODED_SERVICE_KEY = \"h9Dbf2cz0HOrqZb5BIqrfrti%2FD5zZLTYAxFpQuywAB7ZUx3yb67jBDuD5uNlHvAszz9c14NffOmMNQjGv5FzwA%3D%3D\"\n",
    "SERVICE_KEY = urllib.parse.unquote(ENCODED_SERVICE_KEY)\n",
    "BASE_URL = \"https://apis.data.go.kr/1471000/DURPrdlstInfoService03/getMdctnPdAtentInfoList03\"\n",
    "BRONZE_TABLE_NAME = \"main.default.dur_product_duration_bronze\"\n",
    "\n",
    "print(f\"\\nTarget API: {BASE_URL}\")\n",
    "print(f\"Bronze table: {BRONZE_TABLE_NAME}\")\n",
    "print(f\"Expected records: 642\")\n",
    "\n",
    "def make_api_call(page_no, num_rows=100):\n",
    "    \"\"\"Make a single API call with error handling\"\"\"\n",
    "    params = {\n",
    "        \"serviceKey\": SERVICE_KEY,\n",
    "        \"pageNo\": page_no,\n",
    "        \"numOfRows\": num_rows,\n",
    "        \"type\": \"json\"\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "        'Accept': 'application/json, */*',\n",
    "        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        header = data.get(\"header\", {})\n",
    "        if header.get(\"resultCode\") != \"00\":\n",
    "            raise Exception(f\"API Error: {header.get('resultMsg', 'Unknown error')}\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå API call error on page {page_no}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def clean_record(record):\n",
    "    \"\"\"Clean and standardize a single record\"\"\"\n",
    "    cleaned = {}\n",
    "    for key, value in record.items():\n",
    "        # Convert None to empty string for consistency\n",
    "        if value is None:\n",
    "            cleaned[key] = \"\"\n",
    "        # Ensure all values are strings to avoid type conflicts\n",
    "        else:\n",
    "            cleaned[key] = str(value)\n",
    "    return cleaned\n",
    "\n",
    "def extract_all_data():\n",
    "    \"\"\"Extract all data with data cleaning\"\"\"\n",
    "    print(f\"\\nüì• Extracting all data with schema fixing...\")\n",
    "    \n",
    "    all_records = []\n",
    "    page_no = 1\n",
    "    total_count = None\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            if page_no > 1:\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            data = make_api_call(page_no, 100)\n",
    "            \n",
    "            body = data.get(\"body\", {})\n",
    "            if total_count is None:\n",
    "                total_count = body.get(\"totalCount\", 0)\n",
    "                print(f\"   üìä Total records: {total_count:,}\")\n",
    "            \n",
    "            items = body.get(\"items\", [])\n",
    "            \n",
    "            if not items:\n",
    "                break\n",
    "            \n",
    "            # Clean each record to ensure consistent schema\n",
    "            cleaned_items = [clean_record(item) for item in items]\n",
    "            all_records.extend(cleaned_items)\n",
    "            \n",
    "            print(f\"   ‚úÖ Page {page_no}: +{len(items)} records | Total: {len(all_records):,}\")\n",
    "            \n",
    "            if len(all_records) >= total_count:\n",
    "                break\n",
    "            \n",
    "            page_no += 1\n",
    "            \n",
    "            if page_no > 15:\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error on page {page_no}: {str(e)}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"   üéâ Extraction complete: {len(all_records):,}/{total_count:,} records\")\n",
    "    return all_records, total_count\n",
    "\n",
    "def create_explicit_schema():\n",
    "    \"\"\"Define explicit schema based on expected DUR product fields\"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"TYPE_NAME\", StringType(), True),\n",
    "        StructField(\"MIX_TYPE\", StringType(), True),\n",
    "        StructField(\"INGR_CODE\", StringType(), True),\n",
    "        StructField(\"INGR_ENG_NAME\", StringType(), True),\n",
    "        StructField(\"INGR_NAME\", StringType(), True),\n",
    "        StructField(\"MIX_INGR\", StringType(), True),\n",
    "        StructField(\"FORM_NAME\", StringType(), True),\n",
    "        StructField(\"ITEM_SEQ\", StringType(), True),\n",
    "        StructField(\"ITEM_NAME\", StringType(), True),\n",
    "        StructField(\"ITEM_PERMIT_DATE\", StringType(), True),\n",
    "        StructField(\"ENTP_NAME\", StringType(), True),\n",
    "        StructField(\"CHART\", StringType(), True),\n",
    "        StructField(\"CLASS_CODE\", StringType(), True),\n",
    "        StructField(\"CLASS_NAME\", StringType(), True),\n",
    "        StructField(\"ETC_OTC_NAME\", StringType(), True),\n",
    "        StructField(\"MAIN_INGR\", StringType(), True),\n",
    "        StructField(\"NOTIFICATION_DATE\", StringType(), True),\n",
    "        StructField(\"PROHBT_CONTENT\", StringType(), True),\n",
    "        StructField(\"REMARK\", StringType(), True),\n",
    "        StructField(\"INGR_ENG_NAME_FULL\", StringType(), True),\n",
    "        StructField(\"CHANGE_DATE\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "def analyze_data_structure(records):\n",
    "    \"\"\"Analyze data structure with explicit schema\"\"\"\n",
    "    if not records:\n",
    "        print(\"   ‚ùå No records to analyze\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nüî¨ Analyzing data structure with fixed schema...\")\n",
    "    \n",
    "    try:\n",
    "        # Method 1: Use explicit schema\n",
    "        schema = create_explicit_schema()\n",
    "        df = spark.createDataFrame(records, schema)\n",
    "        \n",
    "        print(f\"   ‚úÖ DataFrame created successfully!\")\n",
    "        print(f\"   üìä Records: {df.count():,}\")\n",
    "        print(f\"   üìã Columns: {len(df.columns)}\")\n",
    "        \n",
    "        print(f\"\\n   üìã Schema:\")\n",
    "        df.printSchema()\n",
    "        \n",
    "        print(f\"\\n   üìù Sample records (first 3):\")\n",
    "        df.select(\"ITEM_NAME\", \"ENTP_NAME\", \"INGR_NAME\", \"FORM_NAME\", \"CLASS_NAME\").show(3, truncate=False)\n",
    "        \n",
    "        # Data quality analysis\n",
    "        print(f\"\\n   üîç Data Quality Analysis:\")\n",
    "        key_fields = [\"ITEM_NAME\", \"ENTP_NAME\", \"INGR_NAME\", \"FORM_NAME\"]\n",
    "        \n",
    "        for field in key_fields:\n",
    "            non_empty_count = df.filter((col(field) != \"\") & col(field).isNotNull()).count()\n",
    "            print(f\"      {field}: {non_empty_count}/{df.count()} non-empty ({non_empty_count/df.count()*100:.1f}%)\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error with explicit schema: {str(e)}\")\n",
    "        \n",
    "        # Method 2: Alternative approach with JSON\n",
    "        try:\n",
    "            print(f\"   üîÑ Trying alternative approach with JSON strings...\")\n",
    "            \n",
    "            # Convert records to JSON strings and back to handle schema issues\n",
    "            json_strings = [json.dumps(record) for record in records]\n",
    "            json_rdd = spark.sparkContext.parallelize(json_strings)\n",
    "            df = spark.read.json(json_rdd)\n",
    "            \n",
    "            print(f\"   ‚úÖ Alternative method successful!\")\n",
    "            print(f\"   üìä Records: {df.count():,}\")\n",
    "            print(f\"   üìã Columns: {len(df.columns)}\")\n",
    "            \n",
    "            df.printSchema()\n",
    "            return df\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"   ‚ùå Alternative method also failed: {str(e2)}\")\n",
    "            return None\n",
    "\n",
    "def create_bronze_table(records, df=None):\n",
    "    \"\"\"Create bronze table with cleaned data\"\"\"\n",
    "    print(f\"\\nüíæ Creating bronze table...\")\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"   ‚ùå No DataFrame to save\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Write to bronze table\n",
    "        df.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .saveAsTable(BRONZE_TABLE_NAME)\n",
    "        \n",
    "        print(f\"   ‚úÖ Bronze table created: {BRONZE_TABLE_NAME}\")\n",
    "        \n",
    "        # Verify\n",
    "        bronze_df = spark.table(BRONZE_TABLE_NAME)\n",
    "        verified_count = bronze_df.count()\n",
    "        \n",
    "        print(f\"\\n   üìä Verification:\")\n",
    "        print(f\"      Records in table: {verified_count:,}\")\n",
    "        print(f\"      Columns: {len(bronze_df.columns)}\")\n",
    "        print(f\"      Data integrity: {'‚úÖ Perfect' if verified_count == len(records) else '‚ö†Ô∏è Check needed'}\")\n",
    "        \n",
    "        # Business insights\n",
    "        print(f\"\\n   üìà Business Insights:\")\n",
    "        \n",
    "        # Top enterprises\n",
    "        print(f\"      Top enterprises:\")\n",
    "        bronze_df.groupBy(\"ENTP_NAME\") \\\n",
    "                .count() \\\n",
    "                .orderBy(desc(\"count\")) \\\n",
    "                .show(5, truncate=False)\n",
    "        \n",
    "        # Drug forms\n",
    "        print(f\"      Drug forms:\")\n",
    "        bronze_df.groupBy(\"FORM_NAME\") \\\n",
    "                .count() \\\n",
    "                .orderBy(desc(\"count\")) \\\n",
    "                .show(5, truncate=False)\n",
    "        \n",
    "        # Class distribution\n",
    "        print(f\"      Drug classes:\")\n",
    "        bronze_df.groupBy(\"CLASS_NAME\") \\\n",
    "                .count() \\\n",
    "                .orderBy(desc(\"count\")) \\\n",
    "                .show(5, truncate=False)\n",
    "        \n",
    "        return BRONZE_TABLE_NAME\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error creating bronze table: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution with schema fixes\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"üîß FIXED VERSION: Handling schema inference issues\")\n",
    "    \n",
    "    try:\n",
    "        # Extract all data\n",
    "        all_records, total_count = extract_all_data()\n",
    "        \n",
    "        if not all_records:\n",
    "            print(f\"\\n‚ùå No data extracted.\")\n",
    "            return False\n",
    "        \n",
    "        # Analyze data structure with fixes\n",
    "        df = analyze_data_structure(all_records)\n",
    "        \n",
    "        if df is None:\n",
    "            print(f\"\\n‚ùå Could not create DataFrame.\")\n",
    "            return False\n",
    "        \n",
    "        # Create bronze table\n",
    "        bronze_table = create_bronze_table(all_records, df)\n",
    "        \n",
    "        # Final results\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        print(f\"\\nüéâ === FIXED TEST COMPLETED SUCCESSFULLY ===\")\n",
    "        print(f\"üìä Results:\")\n",
    "        print(f\"   ‚úÖ API extraction: Perfect ({len(all_records):,} records)\")\n",
    "        print(f\"   ‚úÖ Schema handling: Fixed\")\n",
    "        print(f\"   ‚úÖ Bronze table: {bronze_table}\")\n",
    "        print(f\"   üìà Completeness: {len(all_records)/total_count*100:.1f}%\")\n",
    "        print(f\"   ‚è±Ô∏è Processing time: {processing_time:.1f} seconds\")\n",
    "        \n",
    "        print(f\"\\nüöÄ Next Steps:\")\n",
    "        print(f\"   1. ‚úÖ Schema issues resolved\")\n",
    "        print(f\"   2. ‚úÖ Product API pattern established\")\n",
    "        print(f\"   3. üöÄ Ready for comprehensive extraction of all 9 APIs\")\n",
    "        print(f\"   4. üìã Use explicit schema approach for consistency\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nüí• FIXED TEST FAILED: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Execute the fixed test\n",
    "if __name__ == \"__main__\":\n",
    "    success = main()\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\n‚úÖ SCHEMA ISSUES FIXED - Ready for comprehensive extraction!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Still need to debug schema issues\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dur_product_test_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
