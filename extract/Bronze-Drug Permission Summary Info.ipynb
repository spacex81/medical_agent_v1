{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06a01bc2-2cab-43aa-ae2f-f8fb70ec2575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "base_path = '/Volumes/main/default/medical_data_volume/medical_data_complete_unzipped/medical_data_local/drug-product-permission-summary-info/'\n",
    "\n",
    "print(\"=== DRUG PRODUCT PERMISSION SUMMARY INFO - EXPLORATION ===\")\n",
    "\n",
    "# Check directory and files\n",
    "print(f\"\\n1. Checking directory: {base_path}\")\n",
    "\n",
    "try:\n",
    "    files = dbutils.fs.ls(base_path)\n",
    "    json_files = [f for f in files if f.name.endswith('.json') and f.name.startswith('chunk_')]\n",
    "    json_files.sort(key=lambda x: int(x.name.split('_')[1].split('.')[0]))\n",
    "    \n",
    "    print(f\"Found {len(json_files)} JSON files\")\n",
    "    \n",
    "    # Check expected files (chunk_001.json to chunk_012.json)\n",
    "    expected_files = [f\"chunk_{i:03d}.json\" for i in range(1, 13)]\n",
    "    actual_files = [f.name for f in json_files]\n",
    "    \n",
    "    missing_files = set(expected_files) - set(actual_files)\n",
    "    extra_files = set(actual_files) - set(expected_files)\n",
    "    \n",
    "    print(f\"\\n2. File Inventory:\")\n",
    "    print(f\"   Expected files: 12 (chunk_001.json to chunk_012.json)\")\n",
    "    print(f\"   Found files: {len(actual_files)}\")\n",
    "    print(f\"   Missing files: {len(missing_files)}\")\n",
    "    print(f\"   Extra files: {len(extra_files)}\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"   Missing: {sorted(list(missing_files))}\")\n",
    "    if extra_files:\n",
    "        print(f\"   Extra: {sorted(list(extra_files))}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR accessing directory: {str(e)}\")\n",
    "\n",
    "# Test sample files for schema consistency\n",
    "test_files = [\n",
    "    'chunk_001.json',  # First file\n",
    "    'chunk_006.json',  # Middle file\n",
    "    'chunk_012.json'   # Last file\n",
    "]\n",
    "\n",
    "schemas = {}\n",
    "record_counts = {}\n",
    "successful_reads = []\n",
    "failed_reads = []\n",
    "\n",
    "print(f\"\\n3. Testing {len(test_files)} sample files for schema consistency:\")\n",
    "\n",
    "for file_name in test_files:\n",
    "    file_path = f\"{base_path}{file_name}\"\n",
    "    print(f\"\\n   Testing: {file_name}\")\n",
    "    \n",
    "    try:\n",
    "        df = spark.read.option(\"multiline\", \"true\").option(\"encoding\", \"UTF-8\").json(file_path)\n",
    "        schema = df.schema\n",
    "        count = df.count()\n",
    "        \n",
    "        schemas[file_name] = schema\n",
    "        record_counts[file_name] = count\n",
    "        successful_reads.append(file_name)\n",
    "        \n",
    "        print(f\"   ‚úÖ Success - Records: {count:,}, Columns: {len(schema.fields)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed_reads.append((file_name, str(e)))\n",
    "        print(f\"   ‚ùå Failed - Error: {str(e)}\")\n",
    "\n",
    "print(f\"\\n4. Schema Validation Results:\")\n",
    "print(f\"   Successful reads: {len(successful_reads)}\")\n",
    "print(f\"   Failed reads: {len(failed_reads)}\")\n",
    "\n",
    "if failed_reads:\n",
    "    print(f\"   Failed files:\")\n",
    "    for file_name, error in failed_reads:\n",
    "        print(f\"     {file_name}: {error}\")\n",
    "\n",
    "if successful_reads:\n",
    "    # Compare schemas\n",
    "    reference_file = successful_reads[0]\n",
    "    reference_schema = schemas[reference_file]\n",
    "    reference_fields = {field.name: field.dataType for field in reference_schema.fields}\n",
    "    \n",
    "    print(f\"\\n5. Schema Consistency Analysis:\")\n",
    "    print(f\"   Reference schema from: {reference_file}\")\n",
    "    print(f\"   Reference columns: {len(reference_fields)}\")\n",
    "    \n",
    "    all_schemas_match = True\n",
    "    \n",
    "    for file_name in successful_reads[1:]:\n",
    "        current_schema = schemas[file_name]\n",
    "        current_fields = {field.name: field.dataType for field in current_schema.fields}\n",
    "        \n",
    "        ref_columns = set(reference_fields.keys())\n",
    "        curr_columns = set(current_fields.keys())\n",
    "        \n",
    "        missing_in_current = ref_columns - curr_columns\n",
    "        extra_in_current = curr_columns - ref_columns\n",
    "        \n",
    "        type_differences = []\n",
    "        common_columns = ref_columns & curr_columns\n",
    "        for col in common_columns:\n",
    "            if reference_fields[col] != current_fields[col]:\n",
    "                type_differences.append((col, reference_fields[col], current_fields[col]))\n",
    "        \n",
    "        if missing_in_current or extra_in_current or type_differences:\n",
    "            all_schemas_match = False\n",
    "        \n",
    "        print(f\"   {file_name}: Columns={len(current_fields)} \", end=\"\")\n",
    "        if missing_in_current or extra_in_current or type_differences:\n",
    "            print(\"‚ùå Schema differs\")\n",
    "        else:\n",
    "            print(\"‚úÖ Schema matches\")\n",
    "    \n",
    "    print(f\"\\n6. Complete Schema from {reference_file}:\")\n",
    "    reference_df = spark.read.option(\"multiline\", \"true\").option(\"encoding\", \"UTF-8\").json(f\"{base_path}{reference_file}\")\n",
    "    reference_df.printSchema()\n",
    "    \n",
    "    print(f\"\\n7. Record Count Analysis:\")\n",
    "    total_estimated_records = 0\n",
    "    for file_name in successful_reads:\n",
    "        count = record_counts[file_name]\n",
    "        print(f\"   {file_name}: {count:,} records\")\n",
    "        total_estimated_records += count\n",
    "    \n",
    "    avg_records = total_estimated_records / len(successful_reads)\n",
    "    estimated_total = avg_records * 12  # All 12 files\n",
    "    \n",
    "    print(f\"\\n   Average records per file: {avg_records:,.0f}\")\n",
    "    print(f\"   Estimated total records (12 files): {estimated_total:,.0f}\")\n",
    "    \n",
    "    print(f\"\\n8. Sample Data from {reference_file}:\")\n",
    "    reference_df.show(3, truncate=False)\n",
    "    \n",
    "    print(f\"\\n9. Key Field Analysis:\")\n",
    "    # Check what kind of summary data this contains\n",
    "    sample_columns = reference_df.columns[:10]  # First 10 columns\n",
    "    print(f\"   First 10 columns: {sample_columns}\")\n",
    "    \n",
    "    # Look for summary-related fields\n",
    "    summary_keywords = ['TOTAL', 'COUNT', 'SUM', 'AVG', 'SUMMARY', 'CNT']\n",
    "    summary_cols = [col for col in reference_df.columns if any(keyword in col.upper() for keyword in summary_keywords)]\n",
    "    if summary_cols:\n",
    "        print(f\"   Summary-related columns: {summary_cols}\")\n",
    "    \n",
    "    print(f\"\\n=== EXPLORATION COMPLETE ===\")\n",
    "    \n",
    "    if all_schemas_match and len(successful_reads) >= 2:\n",
    "        print(f\"‚úÖ RECOMMENDATION: Use wildcard pattern approach - schemas are consistent\")\n",
    "        print(f\"   Ready for bronze table creation\")\n",
    "    elif len(successful_reads) >= 2:\n",
    "        print(f\"‚ö†Ô∏è  RECOMMENDATION: Use union approach with schema handling\")\n",
    "    else:\n",
    "        print(f\"‚ùå RECOMMENDATION: Investigate file access issues\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ùå No files could be read successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9fe66d5-ad6b-49ba-9454-0e99cc2cf463",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "print(\"=== DRUG PRODUCT PERMISSION SUMMARY INFO - BRONZE TABLE CREATION ===\")\n",
    "\n",
    "# Configuration\n",
    "base_path = '/Volumes/main/default/medical_data_volume/medical_data_complete_unzipped/medical_data_local/drug-product-permission-summary-info/'\n",
    "wildcard_path = f\"{base_path}chunk_*.json\"\n",
    "bronze_table_name = \"main.default.drug_product_permission_summary_bronze\"\n",
    "\n",
    "print(f\"\\nSource path: {wildcard_path}\")\n",
    "print(f\"Target table: {bronze_table_name}\")\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"\\n1. Reading all 12 JSON files using wildcard pattern...\")\n",
    "try:\n",
    "    # Read all files at once using wildcard pattern\n",
    "    df = spark.read \\\n",
    "        .option(\"multiline\", \"true\") \\\n",
    "        .option(\"encoding\", \"UTF-8\") \\\n",
    "        .json(wildcard_path)\n",
    "    \n",
    "    print(f\"‚úÖ Successfully read all files\")\n",
    "    \n",
    "    # Quick validation\n",
    "    total_records = df.count()\n",
    "    total_columns = len(df.columns)\n",
    "    \n",
    "    print(f\"   Total records: {total_records:,}\")\n",
    "    print(f\"   Total columns: {total_columns}\")\n",
    "    \n",
    "    print(f\"\\n2. Data Quality Checks:\")\n",
    "    \n",
    "    # Check for null values in key columns\n",
    "    key_columns = [\"ITEM_SEQ\", \"ITEM_NAME\", \"ENTP_NAME\", \"ITEM_PERMIT_DATE\", \"PRDUCT_TYPE\"]\n",
    "    for col_name in key_columns:\n",
    "        null_count = df.filter(col(col_name).isNull() | (col(col_name) == \"\")).count()\n",
    "        print(f\"   {col_name}: {null_count:,} null/empty values\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    distinct_records = df.distinct().count()\n",
    "    duplicate_count = total_records - distinct_records\n",
    "    print(f\"   Duplicate records: {duplicate_count:,}\")\n",
    "    \n",
    "    # Show schema overview\n",
    "    print(f\"\\n3. Schema Overview (21 columns):\")\n",
    "    schema_fields = df.dtypes\n",
    "    print(f\"   Core summary columns:\")\n",
    "    core_cols = [\"ITEM_SEQ\", \"ITEM_NAME\", \"ENTP_NAME\", \"ITEM_PERMIT_DATE\", \n",
    "                \"PRDUCT_TYPE\", \"ITEM_INGR_CNT\", \"PERMIT_KIND_CODE\", \"SPCLTY_PBLC\"]\n",
    "    for col_name in core_cols:\n",
    "        col_type = dict(schema_fields)[col_name] if col_name in dict(schema_fields) else \"Not found\"\n",
    "        print(f\"     {col_name}: {col_type}\")\n",
    "    \n",
    "    print(f\"\\n4. Creating Bronze Table...\")\n",
    "    \n",
    "    # Write to Delta table\n",
    "    df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(bronze_table_name)\n",
    "    \n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Successfully created bronze table\")\n",
    "    print(f\"   Processing time: {processing_time:.2f} seconds\")\n",
    "    print(f\"   Records per second: {total_records/processing_time:,.0f}\")\n",
    "    \n",
    "    print(f\"\\n5. Bronze Table Verification:\")\n",
    "    \n",
    "    # Verify the table was created\n",
    "    bronze_df = spark.table(bronze_table_name)\n",
    "    verified_count = bronze_df.count()\n",
    "    \n",
    "    print(f\"   Records in bronze table: {verified_count:,}\")\n",
    "    print(f\"   Data integrity: {'‚úÖ Passed' if verified_count == total_records else '‚ùå Failed'}\")\n",
    "    \n",
    "    print(f\"\\n6. Sample Data from Bronze Table:\")\n",
    "    bronze_df.select(\n",
    "        \"ITEM_NAME\", \n",
    "        \"ENTP_NAME\", \n",
    "        \"ITEM_PERMIT_DATE\",\n",
    "        \"PRDUCT_TYPE\",\n",
    "        \"ITEM_INGR_CNT\",\n",
    "        \"SPCLTY_PBLC\"\n",
    "    ).show(5, truncate=False)\n",
    "    \n",
    "    print(f\"\\n7. Business Intelligence Summary:\")\n",
    "    \n",
    "    # Product type distribution\n",
    "    print(f\"   Product Type Distribution:\")\n",
    "    bronze_df.groupBy(\"PRDUCT_TYPE\") \\\n",
    "        .count() \\\n",
    "        .orderBy(col(\"count\").desc()) \\\n",
    "        .show(10, truncate=False)\n",
    "    \n",
    "    # Specialty public classification\n",
    "    print(f\"   Specialty Public Classification:\")\n",
    "    bronze_df.groupBy(\"SPCLTY_PBLC\") \\\n",
    "        .count() \\\n",
    "        .orderBy(col(\"count\").desc()) \\\n",
    "        .show(10, truncate=False)\n",
    "    \n",
    "    # Top enterprises by product count\n",
    "    print(f\"   Top 10 Enterprises by Product Count:\")\n",
    "    bronze_df.groupBy(\"ENTP_NAME\") \\\n",
    "        .agg(countDistinct(\"ITEM_SEQ\").alias(\"unique_products\"),\n",
    "             count(\"*\").alias(\"total_records\")) \\\n",
    "        .orderBy(col(\"unique_products\").desc()) \\\n",
    "        .show(10, truncate=False)\n",
    "    \n",
    "    # Ingredient count distribution\n",
    "    print(f\"   Product Ingredient Count Distribution:\")\n",
    "    bronze_df.filter(col(\"ITEM_INGR_CNT\").isNotNull() & (col(\"ITEM_INGR_CNT\") != \"\")) \\\n",
    "        .groupBy(\"ITEM_INGR_CNT\") \\\n",
    "        .count() \\\n",
    "        .orderBy(col(\"ITEM_INGR_CNT\").cast(\"int\")) \\\n",
    "        .show(20, truncate=False)\n",
    "    \n",
    "    # Permit kind distribution\n",
    "    print(f\"   Permit Kind Code Distribution:\")\n",
    "    bronze_df.groupBy(\"PERMIT_KIND_CODE\") \\\n",
    "        .count() \\\n",
    "        .orderBy(col(\"count\").desc()) \\\n",
    "        .show(10, truncate=False)\n",
    "    \n",
    "    # Products with images\n",
    "    image_count = bronze_df.filter(col(\"BIG_PRDT_IMG_URL\").isNotNull() & (col(\"BIG_PRDT_IMG_URL\") != \"\")).count()\n",
    "    print(f\"\\n   Products with images: {image_count:,} ({image_count/total_records*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n=== INGESTION COMPLETED SUCCESSFULLY ===\")\n",
    "    print(f\"üéâ Bronze table '{bronze_table_name}' created with {verified_count:,} records\")\n",
    "    print(f\"üìä Ready for silver layer transformations and summary analysis\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR during ingestion: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    \n",
    "    # Provide debugging info\n",
    "    print(f\"\\nDebugging information:\")\n",
    "    print(f\"- Verify all 12 files are accessible\")\n",
    "    print(f\"- Check Spark cluster memory (21 columns √ó 35K records)\")\n",
    "    print(f\"- Consider batch processing if memory constraints exist\")\n",
    "    \n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze-Drug Permission Summary Info",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
